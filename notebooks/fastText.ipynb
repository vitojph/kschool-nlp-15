{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo de `fastText` con `gensim`\n",
    "\n",
    "\n",
    "En este cuaderno replicamos [las operaciones con los vectores de Word2Vec](word2vec.ipynb) pero utilizando los [vectores de palabras `fastText`](https://fasttext.cc/docs/en/crawl-vectors.html), entrenados por Facebook AI utilizando [Common Crawl](https://commoncrawl.org/) y Wikipedia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero, es asegurarnos de que hemos descargado los vectores preentrenados. Si no lo has hecho antes, descarga y descomprime [la versión en texto plan con extensión `vec` de los vectores en español](https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz\n",
    "#!gunzip cc.es.300.vec.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los modelos usando `gensim`. Paciencia, esta operación tarda varios minutos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-21 19:39:27,755 : INFO : loading projection weights from /home/victor/data/fasttext/cc.es.300.vec\n",
      "2019-07-21 19:39:27,760 : WARNING : this function is deprecated, use smart_open.open instead\n",
      "2019-07-21 19:48:40,637 : INFO : loaded (2000000, 300) matrix from /home/victor/data/fasttext/cc.es.300.vec\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format(\"/home/victor/data/fasttext/cc.es.300.vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probando nuestro modelo\n",
    "\n",
    "El objeto `model` contiene una enorme matriz de números: una tabla, donde cada fila es uno de los términos del vocabulario reconocido y cada columna es una de las características que permiten modelar el significado de dicho término.\n",
    "\n",
    "Cada término del vocabulario está representado como un vector con 300 dimensiones. Como en `word2vec`, estos vectors son densos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.500e-03 -6.800e-03  7.120e-02 -1.757e-01  2.420e-02 -2.310e-02\n",
      "  4.140e-02  5.100e-03  2.760e-02 -6.410e-02  1.608e-01 -7.210e-02\n",
      "  9.870e-02  1.394e-01 -1.339e-01  4.430e-02 -1.440e-02 -4.600e-02\n",
      "  1.570e-02  4.790e-02  2.300e-03  5.350e-02 -4.360e-02  7.870e-02\n",
      " -2.040e-02 -3.250e-02 -3.510e-02 -1.228e-01 -7.700e-02  6.260e-02\n",
      " -7.540e-02 -2.500e-03  2.540e-02  4.900e-02  5.500e-03 -4.200e-02\n",
      " -8.050e-02 -4.510e-02 -1.040e-01  4.830e-02  2.030e-02  8.590e-02\n",
      " -9.100e-03 -1.151e-01 -3.930e-02  5.640e-02  8.470e-02  1.091e-01\n",
      " -4.950e-02  2.000e-02 -6.350e-02  5.320e-02  4.250e-02  8.600e-03\n",
      "  6.660e-02  1.803e-01 -1.090e-02  9.990e-02  1.375e-01  6.540e-02\n",
      " -8.810e-02  4.300e-03  2.520e-02 -4.000e-04  1.213e-01 -6.600e-02\n",
      " -1.602e-01  1.213e-01  3.050e-02 -1.188e-01 -1.636e-01  7.570e-02\n",
      "  5.680e-02  4.920e-02 -9.900e-03  3.750e-02  2.680e-02 -1.840e-02\n",
      "  5.950e-02  6.000e-03  3.940e-02  9.880e-02  6.470e-02 -4.060e-02\n",
      "  4.250e-02  4.360e-02  3.710e-02 -1.070e-01 -8.830e-02 -1.477e-01\n",
      "  1.620e-02 -3.590e-02  1.680e-02  3.100e-03  5.240e-02 -2.690e-02\n",
      " -6.010e-02 -3.400e-03 -2.870e-02 -6.500e-03  1.927e-01 -8.620e-02\n",
      " -1.340e-02  7.590e-02 -1.050e-02  8.800e-03 -4.350e-02  1.970e-02\n",
      "  1.560e-02  6.610e-02  9.920e-02  8.210e-02 -1.331e-01 -2.220e-02\n",
      "  5.100e-03  1.169e-01  9.620e-02 -5.210e-02 -5.010e-02 -4.880e-02\n",
      "  1.000e-01  8.590e-02  7.780e-02 -8.470e-02 -5.210e-02  1.002e-01\n",
      " -2.080e-02  4.560e-02 -1.539e-01  1.810e-02 -1.760e-02  1.341e-01\n",
      "  8.810e-02 -1.860e-02  6.160e-02  1.640e-02  2.210e-02  2.580e-02\n",
      "  1.383e-01 -1.810e-02 -6.170e-02  1.500e-03  2.440e-02  5.130e-02\n",
      " -2.000e-03  2.280e-02  1.545e-01  6.650e-02  9.070e-02 -2.910e-02\n",
      "  8.340e-02  1.653e-01 -1.260e-02 -1.106e-01  5.370e-02 -5.340e-02\n",
      "  7.250e-02  3.170e-02 -9.370e-02  2.050e-02  1.487e-01 -1.960e-02\n",
      "  1.164e-01 -3.290e-02 -3.000e-03 -3.710e-02 -8.660e-02  1.059e-01\n",
      " -1.430e-02  3.600e-02  4.560e-02  8.730e-02  1.130e-02  6.700e-02\n",
      "  7.200e-02  4.860e-02  1.526e-01  8.860e-02  7.100e-03  5.370e-02\n",
      "  1.727e-01  1.015e-01  1.752e-01  1.655e-01  9.340e-02 -9.900e-03\n",
      " -4.310e-02  4.720e-02 -2.710e-02  2.090e-02  4.060e-02  9.350e-02\n",
      "  6.140e-02  4.410e-02 -5.960e-02  2.350e-02 -1.000e-04  9.400e-03\n",
      " -1.003e-01  1.674e-01 -5.170e-02  4.160e-02 -6.910e-02 -6.780e-02\n",
      " -1.690e-02  5.190e-02 -2.100e-03 -2.005e-01 -6.550e-02  7.980e-02\n",
      " -6.040e-02  1.154e-01 -1.145e-01  1.500e-03  2.220e-02  4.060e-02\n",
      " -1.026e-01  2.970e-02  1.346e-01 -1.110e-02  3.040e-02 -1.230e-02\n",
      " -1.110e-02  1.250e-02 -9.560e-02  7.140e-02 -8.310e-02  7.620e-02\n",
      "  7.800e-03 -7.120e-02 -8.050e-02 -1.017e-01 -6.940e-02 -3.990e-02\n",
      " -5.650e-02 -1.474e-01 -1.045e-01 -4.510e-02 -2.890e-02 -2.129e-01\n",
      " -6.600e-03 -4.370e-02 -1.631e-01 -1.184e-01 -1.261e-01  1.270e-02\n",
      "  9.500e-03  1.722e-01  6.240e-02 -7.770e-02  1.550e-01 -8.400e-03\n",
      "  1.404e-01 -6.830e-02 -2.640e-02 -1.010e-02  8.920e-02 -1.030e-02\n",
      " -2.770e-02  8.200e-02 -2.660e-02  1.380e-02 -1.196e-01 -4.590e-02\n",
      " -9.000e-03 -9.880e-02 -3.960e-02  8.610e-02  4.750e-02 -2.740e-02\n",
      " -6.590e-02  1.180e-02 -7.650e-02  7.990e-02  1.201e-01 -1.082e-01\n",
      "  1.048e-01 -1.417e-01 -2.600e-02 -8.000e-04 -6.790e-02 -1.128e-01\n",
      " -3.040e-02 -1.177e-01 -3.180e-02  1.960e-02  6.760e-02 -7.000e-02\n",
      "  3.040e-02 -4.300e-02  4.180e-02 -8.970e-02 -1.041e-01 -2.420e-02\n",
      " -7.320e-02 -8.680e-02  4.070e-02  4.520e-02 -8.140e-02 -1.027e-01] \n",
      "\n",
      "[-8.050e-02 -5.850e-02  4.560e-02 -9.460e-02  4.050e-02  7.500e-03\n",
      "  5.280e-02 -1.700e-02  0.000e+00 -4.160e-02  1.099e-01 -4.590e-02\n",
      "  1.735e-01  4.940e-02 -3.300e-02  2.190e-02 -6.840e-02  6.000e-03\n",
      "  2.560e-02  6.570e-02 -3.210e-02  9.010e-02  1.600e-03  4.700e-02\n",
      " -8.590e-02 -6.820e-02  4.600e-03 -7.500e-03 -7.150e-02  5.340e-02\n",
      "  3.900e-03 -7.100e-03 -4.170e-02  6.960e-02  7.100e-03 -1.650e-02\n",
      " -1.150e-02 -9.800e-02 -5.330e-02  2.180e-02 -3.100e-02  5.820e-02\n",
      " -3.200e-03 -5.360e-02  1.430e-02 -2.470e-02  4.360e-02  3.760e-02\n",
      " -8.230e-02  2.790e-02 -9.380e-02  5.010e-02  3.260e-02  1.650e-02\n",
      "  9.340e-02  1.412e-01  6.340e-02  1.254e-01  9.910e-02 -1.770e-02\n",
      " -4.700e-03 -3.360e-02  2.720e-02  2.710e-02  4.570e-02 -5.670e-02\n",
      " -1.343e-01  8.250e-02  1.330e-02 -8.790e-02 -4.640e-02 -4.300e-03\n",
      "  8.520e-02 -6.400e-03 -1.240e-02 -6.850e-02  4.850e-02 -3.320e-02\n",
      "  6.600e-03  1.470e-02  4.750e-02  2.300e-02  9.530e-02 -2.420e-02\n",
      "  3.230e-02 -3.900e-03 -5.370e-02 -2.090e-02 -5.300e-02 -1.502e-01\n",
      "  1.490e-02 -2.990e-02 -5.450e-02  6.600e-03  1.075e-01  5.180e-02\n",
      " -2.900e-02  3.380e-02  1.400e-03 -5.550e-02  4.840e-02  6.300e-03\n",
      " -1.320e-02  5.450e-02 -9.000e-04  1.350e-02  2.710e-02 -2.000e-03\n",
      " -8.700e-03  1.860e-02  5.130e-02  6.020e-02 -5.670e-02  3.940e-02\n",
      "  5.710e-02  1.261e-01  2.720e-02  2.960e-02 -3.770e-02 -3.330e-02\n",
      "  3.680e-02  6.550e-02  5.790e-02 -9.050e-02 -7.490e-02  2.190e-02\n",
      " -2.850e-02  5.100e-02 -1.189e-01  2.390e-02 -7.920e-02  9.100e-02\n",
      "  3.310e-02  5.180e-02 -4.510e-02  3.740e-02  3.520e-02  3.940e-02\n",
      "  7.500e-02 -4.960e-02  1.330e-02 -8.100e-03  4.710e-02  3.230e-02\n",
      " -2.800e-03 -1.620e-02  1.088e-01  6.090e-02  2.080e-02  8.500e-03\n",
      "  5.400e-02  1.241e-01  1.770e-02 -7.670e-02  1.610e-02 -5.540e-02\n",
      "  4.360e-02 -6.490e-02 -2.600e-02  9.100e-03  8.410e-02  1.220e-02\n",
      "  8.500e-02 -3.170e-02 -4.880e-02 -1.000e-03 -4.660e-02  6.250e-02\n",
      " -2.000e-02  5.380e-02  2.080e-02  6.890e-02  5.600e-03  4.180e-02\n",
      "  1.171e-01  3.280e-02  1.336e-01  4.960e-02  9.700e-03 -3.330e-02\n",
      "  1.678e-01  4.920e-02  7.610e-02  9.000e-02  2.790e-02  1.250e-02\n",
      " -1.710e-02  3.380e-02 -3.530e-02  4.440e-02  3.330e-02  5.150e-02\n",
      "  8.410e-02  4.100e-03 -4.370e-02  1.920e-02  4.300e-03 -2.630e-02\n",
      " -3.810e-02  1.281e-01 -2.180e-02 -1.060e-02 -9.000e-02 -5.870e-02\n",
      " -4.490e-02  6.710e-02 -7.800e-03 -1.382e-01 -3.700e-02  6.100e-03\n",
      " -5.050e-02  1.610e-02 -8.090e-02  2.740e-02 -5.400e-03 -2.290e-02\n",
      " -5.710e-02  5.500e-03  6.580e-02  1.000e-04  1.070e-02 -4.590e-02\n",
      " -2.880e-02  3.660e-02 -3.420e-02  2.890e-02  6.420e-02  9.990e-02\n",
      " -4.890e-02 -1.087e-01 -2.200e-03 -3.130e-02 -9.030e-02 -2.110e-02\n",
      "  9.900e-03 -1.103e-01 -7.020e-02 -4.940e-02 -3.550e-02 -1.036e-01\n",
      " -4.870e-02 -1.030e-02 -1.057e-01 -1.145e-01 -1.270e-01  1.500e-03\n",
      " -6.700e-03  1.746e-01  6.250e-02 -4.610e-02  7.140e-02  2.180e-02\n",
      "  9.120e-02  5.190e-02  5.200e-03 -2.940e-02  2.810e-02  3.610e-02\n",
      " -3.880e-02  2.550e-02  8.180e-02  7.740e-02 -6.720e-02 -4.570e-02\n",
      " -2.750e-02  8.900e-03 -3.430e-02  3.850e-02 -1.170e-02 -1.780e-02\n",
      " -1.160e-02  4.130e-02 -4.250e-02  5.590e-02  8.430e-02 -7.130e-02\n",
      "  4.350e-02 -7.900e-02 -2.050e-02 -1.010e-02 -8.690e-02 -1.020e-01\n",
      " -5.840e-02 -1.056e-01 -1.750e-02 -2.700e-03 -2.500e-03  4.890e-02\n",
      "  4.710e-02 -3.140e-02 -2.230e-02 -5.750e-02 -1.345e-01  4.790e-02\n",
      " -3.020e-02 -2.460e-02  4.460e-02  3.960e-02 -8.270e-02 -6.000e-02] \n",
      "\n",
      "[-4.770e-02  3.740e-02  3.040e-02 -3.010e-02 -1.614e-01  2.980e-02\n",
      "  1.880e-02  8.700e-03  1.490e-02 -1.950e-02  4.680e-02 -1.500e-02\n",
      " -7.970e-02  6.580e-02 -4.400e-02 -1.007e-01  2.400e-03 -2.440e-02\n",
      "  5.240e-02  7.060e-02 -2.350e-02  8.000e-03  1.120e-02  1.200e-02\n",
      " -1.950e-02  1.680e-02 -5.990e-02 -3.500e-03  1.490e-02 -2.260e-02\n",
      "  1.420e-02  5.540e-02  4.990e-02 -1.590e-02  7.730e-02  3.710e-02\n",
      "  5.050e-02 -3.180e-02  2.330e-02 -1.570e-02 -3.900e-03  8.300e-03\n",
      " -1.390e-02  4.910e-02  3.500e-03 -2.880e-02 -1.000e-04  1.170e-02\n",
      "  2.560e-02  4.160e-02  1.680e-02  2.330e-02 -1.320e-02  2.250e-02\n",
      " -1.000e-04  5.590e-02  5.470e-02  3.200e-02  5.680e-02 -3.070e-02\n",
      "  4.520e-02  7.100e-02 -5.130e-02  4.320e-02 -1.020e-02  3.800e-03\n",
      " -1.470e-02  1.010e-02  1.380e-02 -1.510e-02  4.400e-03  2.990e-02\n",
      "  2.910e-02 -1.610e-02  1.560e-02 -5.400e-02  5.120e-02  2.950e-02\n",
      "  2.660e-02 -9.500e-03  4.000e-02 -6.500e-03  3.800e-03  1.990e-02\n",
      " -1.200e-02  3.770e-02 -5.140e-02  2.390e-02 -2.310e-02 -1.700e-03\n",
      "  5.440e-02 -3.460e-02  2.510e-02  3.200e-03 -1.200e-03 -3.520e-02\n",
      " -6.700e-03  1.980e-02  4.340e-02  1.910e-02  2.050e-02  2.000e-03\n",
      " -3.000e-03 -2.210e-02  4.370e-02  4.610e-02 -6.870e-02 -7.300e-03\n",
      "  3.030e-02  3.470e-02  3.650e-02 -6.300e-02  6.420e-02 -5.160e-02\n",
      "  3.350e-02 -3.100e-03 -6.960e-02  1.000e-04 -3.070e-02 -5.000e-03\n",
      " -5.700e-03  1.860e-02 -3.150e-02  2.560e-02 -3.190e-02  4.140e-02\n",
      " -1.020e-02  7.400e-03  2.700e-03  5.560e-02 -7.020e-02  5.740e-02\n",
      " -3.140e-02  2.980e-02 -3.630e-02 -1.180e-02  8.300e-03  6.700e-02\n",
      "  3.050e-02  1.670e-02  1.440e-02  4.500e-02 -1.610e-02  2.010e-02\n",
      " -5.400e-02 -4.800e-02  9.400e-03 -5.100e-03 -3.480e-02 -3.330e-02\n",
      " -1.210e-02  3.560e-02 -2.130e-02 -7.060e-02  3.310e-02 -5.480e-02\n",
      "  7.140e-02 -1.200e-02 -1.350e-02  4.400e-03 -5.110e-02 -8.900e-03\n",
      "  2.900e-02  5.000e-04  6.750e-02 -1.124e-01 -1.500e-02 -7.540e-02\n",
      "  1.048e-01  1.300e-03 -3.340e-02 -8.500e-03 -2.470e-02 -4.850e-02\n",
      "  1.230e-02  8.050e-02  1.350e-02  3.420e-02  1.460e-02  3.580e-02\n",
      "  1.910e-02  8.300e-03 -1.670e-02  1.240e-02  5.570e-02 -2.390e-02\n",
      "  1.780e-02  1.000e-02  1.030e-02 -1.010e-02  8.700e-03 -1.000e-02\n",
      "  1.320e-02  4.900e-03 -6.400e-02 -2.400e-02 -1.130e-02  7.170e-02\n",
      "  4.600e-03  3.380e-02 -1.630e-02 -4.010e-02 -2.870e-02  6.200e-03\n",
      " -2.040e-02  2.230e-02 -1.080e-02 -9.060e-02 -4.080e-02  3.750e-02\n",
      " -1.900e-02 -3.980e-02  2.000e-03  1.970e-02  3.970e-02 -1.300e-03\n",
      " -5.030e-02  3.110e-02 -3.350e-02  6.400e-03 -2.890e-02 -2.200e-03\n",
      "  3.310e-02  3.940e-02  4.500e-03 -2.210e-02 -6.270e-02  6.100e-03\n",
      "  3.940e-02  1.070e-02 -3.070e-02 -5.940e-02 -2.310e-02  1.750e-02\n",
      "  5.640e-02 -4.700e-03 -4.800e-03  8.850e-02  2.340e-02 -4.570e-02\n",
      " -1.020e-02 -2.280e-02 -3.480e-02 -9.440e-02  1.170e-02 -5.240e-02\n",
      "  1.020e-02  1.940e-02  2.580e-02 -9.300e-03  4.050e-02 -1.170e-02\n",
      "  1.110e-02 -2.000e-02 -6.260e-02 -6.270e-02 -2.600e-03  6.260e-02\n",
      "  4.040e-02 -6.220e-02 -2.120e-02 -3.500e-03  1.660e-02 -1.222e-01\n",
      "  6.300e-03 -4.000e-04 -3.800e-02 -6.800e-02 -6.500e-03  2.080e-02\n",
      " -4.710e-02 -1.100e-02  1.540e-02 -6.720e-02 -3.370e-02 -5.260e-02\n",
      " -2.700e-03  1.810e-02 -2.900e-03  3.600e-02  6.460e-02 -3.500e-03\n",
      "  1.380e-02 -6.500e-02  9.700e-03  1.730e-02 -4.820e-02  1.000e-04\n",
      "  9.100e-03 -6.740e-02  1.260e-02 -4.200e-02 -3.320e-02 -4.720e-02\n",
      " -1.860e-02  2.520e-02 -6.650e-02  6.200e-03  3.430e-02 -2.510e-02]\n"
     ]
    }
   ],
   "source": [
    "print(model[\"azul\"])\n",
    "print(model[\"verde\"])\n",
    "print(model[\"microsoft\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos vectores no nos dicen mucho, salvo que contienen números muy pequeños :-/\n",
    "\n",
    "El mismo objeto `model` permite acceder a una serie de funcionalidades ya implementadas que nos van a permitir evaluar formal e informalmente el modelo. Por el momento, nos contentamos con los segundo: vamos a revisar visualmente los significados que nuestro modelo ha aprendido por su cuenta. \n",
    "\n",
    "Podemos calcular la similitud semántica entre dos términos usando el método `similarity`, que nos devuelve un número entre 0 y 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hombre - mujer 0.6847727\n",
      "perro - gato 0.81946486\n",
      "gato - periódico 0.23872271\n",
      "febrero - azul 0.0820393\n"
     ]
    }
   ],
   "source": [
    "print(\"hombre - mujer\", model.similarity(\"hombre\", \"mujer\"))\n",
    "\n",
    "print(\"perro - gato\", model.similarity(\"perro\", \"gato\"))\n",
    "\n",
    "print(\"gato - periódico\", model.similarity(\"gato\", \"periódico\"))\n",
    "\n",
    "print(\"febrero - azul\", model.similarity(\"febrero\", \"azul\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos seleccionar el término que no encaja a partir de una determinada lista de términos usando el método `doesnt_match`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-21 19:56:01,740 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en la lista ['madrid', 'barcelona', 'gonzález', 'washington'] sobra: gonzález\n",
      "en la lista ['psoe', 'pp', 'ciu', 'ronaldo'] sobra: ronaldo\n",
      "en la lista ['publicaron', 'declararon', 'soy', 'negaron'] sobra: soy\n",
      "en la lista ['homero', 'saturno', 'cervantes', 'shakespeare', 'cela'] sobra: cela\n",
      "en la lista ['madrid', 'barcelona', 'alpedrete', 'marsella'] sobra: alpedrete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victor/.virtualenvs/ds/lib/python3.7/site-packages/gensim/models/keyedvectors.py:876: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    }
   ],
   "source": [
    "lista1 = \"madrid barcelona gonzález washington\".split()\n",
    "print(\"en la lista {} sobra: {}\".format(lista1, model.doesnt_match(lista1)))\n",
    "\n",
    "lista2 = \"psoe pp ciu ronaldo\".split()\n",
    "print(\"en la lista {} sobra: {}\".format(lista2, model.doesnt_match(lista2)))\n",
    "\n",
    "lista3 = \"publicaron declararon soy negaron\".split()\n",
    "print(\"en la lista {} sobra: {}\".format(lista3, model.doesnt_match(lista3)))\n",
    "\n",
    "lista4 = \"homero saturno cervantes shakespeare cela\".split()\n",
    "print(\"en la lista {} sobra: {}\".format(lista4, model.doesnt_match(lista4)))\n",
    "\n",
    "lista5 = \"madrid barcelona alpedrete marsella\".split()\n",
    "print(\"en la lista {} sobra: {}\".format(lista5, model.doesnt_match(lista5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos buscar los términos más similares usando el método `most_similar` de nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psoe ==> [('ppsoe', 0.8005370497703552), ('Psoe', 0.7764014005661011), ('pesoe', 0.7492713332176208), ('rajoy', 0.7394102811813354), ('pnv', 0.6976327896118164), ('aznar', 0.6966044902801514), ('PsoE', 0.6826643943786621), ('PSOE', 0.6822848916053772), ('PSOE.', 0.6781550645828247), ('PSOE.Y', 0.675744354724884)]\n",
      "chicago ==> [('Chicago', 0.6816766262054443), ('Chicago.', 0.6009481549263), ('brooklyn', 0.5926045775413513), ('oakland', 0.5809924602508545), ('seattle', 0.5727728605270386), ('houston', 0.5660635232925415), ('minnesota', 0.5595453977584839), ('manhattan', 0.5574262142181396), ('baltimore', 0.5437635183334351), ('detroit', 0.5420485138893127)]\n",
      "rajoy ==> [('rubalcaba', 0.7588464617729187), ('aznar', 0.7570807337760925), ('psoe', 0.7394102811813354), ('ppsoe', 0.6995846033096313), ('cospedal', 0.6919615268707275), ('merkel', 0.6574246883392334), ('solbes', 0.6568419933319092), ('pnv', 0.6447515487670898), ('Rajoy', 0.6433820128440857), ('barcenas', 0.6415294408798218)]\n",
      "enero ==> [('febrero', 0.9748411774635315), ('marzo', 0.967797577381134), ('diciembre', 0.9676311016082764), ('abril', 0.961513876914978), ('julio', 0.959632158279419), ('noviembre', 0.9578108191490173), ('octubre', 0.9571519494056702), ('junio', 0.9564434289932251), ('septiembre', 0.9544823169708252), ('agosto', 0.951358437538147)]\n",
      "amarillo ==> [('rojo', 0.855312168598175), ('anaranjado', 0.8112099170684814), ('azul', 0.7992109060287476), ('verde', 0.7389023900032043), ('morado', 0.7388806343078613), ('amarilo', 0.7236419916152954), ('amarrillo', 0.7234234809875488), ('naranja', 0.7144895195960999), ('color', 0.7112823128700256), ('amarilloso', 0.7027315497398376)]\n",
      "microsoft ==> [('microsoft.', 0.7593238353729248), ('Microsoft', 0.7455927133560181), ('mocosoft', 0.7293276786804199), ('microsof', 0.7135891318321228), ('microsft', 0.700303316116333), ('MIcrosoft', 0.6993333697319031), ('windows', 0.649368405342102), ('ballmer', 0.6446675062179565), ('Mocosoft', 0.622758150100708), ('Micrososft', 0.6222069263458252)]\n",
      "iberia ==> [('Iberia', 0.6157836318016052), ('iberian', 0.5768893957138062), ('iberia.com', 0.5603300333023071), ('iber', 0.5538694858551025), ('avianca', 0.5458202362060547), ('ryanair', 0.5422438383102417), ('iberica', 0.5319492816925049), ('spanair', 0.5309250354766846), ('hispania', 0.5269148349761963), ('lufthansa', 0.5165303349494934)]\n",
      "ronaldo ==> [('ronaldiño', 0.7712291479110718), ('messi', 0.7526427507400513), ('ronaldinho', 0.750967264175415), ('3bdo', 0.6910356283187866), ('neymar', 0.689631462097168), ('benzema', 0.6620233058929443), ('ronaldos', 0.6573012471199036), ('mourinho', 0.6448709964752197), ('cr7', 0.6316920518875122), ('zidane', 0.6288356184959412)]\n",
      "messi ==> [('neymar', 0.7615854740142822), ('ronaldo', 0.752642810344696), ('maradona', 0.7426437139511108), ('ronaldinho', 0.7365755438804626), ('higuain', 0.7192940711975098), ('Messi', 0.7070342898368835), ('cr7', 0.7035968899726868), ('benzema', 0.70054030418396), ('ronaldiño', 0.6984191536903381), ('Messi.', 0.6885377168655396)]\n",
      "atlético ==> [('atletico', 0.6924890875816345), ('atléticos', 0.6503394246101379), ('atlética', 0.6465539932250977), ('musculoso', 0.6313217878341675), ('deportivo', 0.6274149417877197), ('musculado', 0.6191726922988892), ('atléticamente', 0.6046326756477356), ('fornido', 0.6045413613319397), ('corpulento', 0.5943037867546082), ('deportista', 0.5809779167175293)]\n",
      "2019 ==> [('2018', 0.8505683541297913), ('2021', 0.8113119006156921), ('2023', 0.788173496723175), ('2020', 0.7852667570114136), ('2022', 0.7646331787109375), ('2024', 0.7141915559768677), ('2019.El', 0.6917481422424316), ('2019.', 0.6897809505462646), ('2019-2020', 0.6881228089332581), ('2025', 0.6649649143218994)]\n"
     ]
    }
   ],
   "source": [
    "terminos = \"psoe chicago rajoy enero amarillo microsoft iberia ronaldo messi atlético 2019\".split()\n",
    "\n",
    "for t in terminos:\n",
    "    print(\"{} ==> {}\".format(t, model.most_similar(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el mismo método `most_similar` podemos combinar vectores de palabras tratando de jugar con los rasgos semánticos de cada una de ellas para descubrir nuevas relaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mujer que ejerce la autoridad en una alcaldía ==> alcalde + mujer - hombre\n",
      "('alcaldesa', 0.8514840602874756)\n",
      "('Alcaldesa', 0.7635220289230347)\n",
      "('alcadesa', 0.7297311425209045)\n",
      "monarca soberano ==> reina + hombre - mujer\n",
      "('rey', 0.6823060512542725)\n",
      "('monarca', 0.6184303760528564)\n",
      "('reino', 0.6015368700027466)\n",
      "capital de Alemania ==> moscú + alemania - rusia\n",
      "('munich', 0.5816982984542847)\n",
      "('austria', 0.5530569553375244)\n",
      "('múnich', 0.5446099042892456)\n",
      "presidente de Francia ==> obama + francia - eeuu\n",
      "('sarkozy', 0.511267364025116)\n",
      "('henri', 0.4758860766887665)\n",
      "('paris', 0.47072291374206543)\n"
     ]
    }
   ],
   "source": [
    "print(\"mujer que ejerce la autoridad en una alcaldía ==> alcalde + mujer - hombre\")\n",
    "most_similar = model.most_similar(positive=[\"alcalde\", \"mujer\"], negative=[\"hombre\"], topn=3)\n",
    "for item in most_similar:\n",
    "    print(item)\n",
    "\n",
    "print(\"monarca soberano ==> reina + hombre - mujer\")    \n",
    "most_similar = model.most_similar(positive=[\"reina\", \"hombre\"], negative=[\"mujer\"], topn=3)\n",
    "for item in most_similar:\n",
    "    print(item)\n",
    "    \n",
    "print(\"capital de Alemania ==> moscú + alemania - rusia\")\n",
    "most_similar = model.most_similar(positive=[\"moscú\", \"alemania\"], negative=[\"rusia\"], topn=3)\n",
    "for item in most_similar:\n",
    "    print(item)\n",
    "\n",
    "print(\"presidente de Francia ==> obama + francia - eeuu\")\n",
    "most_similar = model.most_similar(positive=[\"obama\", \"francia\"], negative=[\"eeuu\"], topn=3)\n",
    "for item in most_similar:\n",
    "    print(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
